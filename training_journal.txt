== 20th May, 11:50am ==
- Trained the model to 1 epoch and snapshotted.
- Resumed training for another 4 epochs.
- Noticed that the loss was increasing at each epoch:
epoch 1: 3.2247357749
epoch 2: 3.3537965479
epoch 3: 3.516193326
epoch 4: 3.6436337303
epoch 5: 3.7643052345

- The first epoch of training is definitely reducing loss, since the
  untrained model has ~0.02% accuracy on the validation set, but after 1 epochs
  training has 31% accuracy.

- Discussed with ChatGPT and we have two main ideas of what could be going wrong:
  1) Training from the 2nd epoch onwards was resumed from snapshot.  Possibly
  there could be a bug in restoring the optimizer state which is causing the
  loss to go up.
  2) The learning rate could be too high, causing training to overshoot.

- I am going to try the following:
 1) Train on 5 epochs without restoring from snapshot in the middle, to test the
    snapshot/restore bug hypothesis.
 2) If the above didn't fix the bug, try reducing learning rate from Adam's
    default (1e-3) to 1e-4.

Results:

1) Snapshot/restore functionality appears to work fine.  The same issue of
increasing loss occured when not using snapshotting.

Here's the results from the v1 model with 1e-3 learning rate:

epoch,training_loss,training_top_5_acc,training_accuracy,validation_f1_score_macro,validation_loss,validation_precision_macro,validation_top_5_accuracy,validation_recall_macro,validation_recall_micro,validation_accuracy,validation_precision_micro,validation_f1_score_micro,validation_top_5_acc
1,3.2315075886,68.928039445,31.3928569014,5.6813152488,3.0792971602,65.4738157559,73.724306521,6.445209268,35.1106114185,35.1106114185,35.1106114185,35.1106114185,
2,3.361339971,72.0446100005,32.8882699315,6.7326739821,3.4026299975,60.6931810296,73.1775474216,8.2992956059,33.0957201638,33.0957201638,33.0957201638,33.0957201638,
3,3.5159329014,73.0584531624,33.326347528,6.7345578681,3.7180197095,60.9107401213,73.6659917706,8.4431275852,33.6368810472,33.6368810472,33.6368810472,33.6368810472,
4,3.6597617971,73.6421059273,33.6738350043,7.5395065363,4.0672946342,57.4465725714,73.6212060423,8.6312476955,32.9497000289,32.9497000289,32.9497000289,32.9497000289,
5,3.7727548355,74.2246319495,34.0794624085,8.5137171176,4.08006612,52.5039431919,74.2570700803,9.9172454909,32.1006372636,32.1006372636,32.1006372636,32.1006372636,
6,3.8662004141,74.6751037167,34.2396852331,,4.2276296166,,,,,34.079606632,,,74.0816593112
7,3.9534126623,75.0180842218,34.4564705458,,4.2171596133,,,,,34.8535599989,,,75.0963359676
8,4.0262200343,75.3721068062,34.7911131543,,4.2361361302,,,,,36.1234220029,,,75.5106039542
9,4.0981813117,75.6558206406,35.0000112674,,4.7706815169,,,,,31.7400188473,,,72.5360851675
10,4.1495278687,75.9528300399,35.247443984,,4.7529160895,,,,,35.6335780998,,,76.0587626076

(missing metrics are because I added some new metrics after the code ran)

== Sun 21st May, 3pm ==
Reducing the learning rate saw the training and validation loss both steadily
trend down, so it looks like the 1e-3 learning rate was overshooting.

However, the new model (lr1e4) appears to be overfitting.  Results:

epoch,training_loss,training_f1_score_macro,training_precision_macro,training_top_5_accuracy,training_recall_macro,training_recall_micro,training_accuracy,training_precision_micro,training_f1_score_micro,validation_f1_score_macro,validation_loss,validation_precision_macro,validation_top_5_accuracy,validation_recall_macro,validation_recall_micro,validation_accuracy,validation_precision_micro,validation_f1_score_micro
1,2.5852090719,3.1206656457,68.8510755771,72.6861773448,2.7691301792,35.9672072779,35.9672072779,35.9672072779,35.9672072779,4.2924570786,2.1305200113,84.7486000743,78.8499398192,3.9149815897,40.9136288569,40.9136288569,40.9136288569,40.9136288569
2,2.073595188,8.4091373642,52.4334464158,79.9469078798,7.2375279044,40.8173842891,40.8173842891,40.8173842891,40.8173842891,9.2007364429,1.9639582348,72.5276034842,81.4405142894,8.0618229005,42.4512721946,42.4512721946,42.4512721946,42.4512721946
3,1.9220939211,13.60625916,49.7204741552,82.2749838312,11.3629908193,42.4394432088,42.4394432088,42.4394432088,42.4394432088,13.366798583,1.8953340608,56.506632693,82.3730837773,13.3805090139,43.0292880002,43.0292880002,43.0292880002,43.0292880002
4,1.8292348324,17.546353651,46.946821161,83.7974386883,14.5386174168,43.5772280775,43.5772280775,43.5772280775,43.5772280775,14.3463529594,1.8590599547,57.6302872128,82.967894231,13.4968189554,43.8447614693,43.8447614693,43.8447614693,43.8447614693
5,1.7616312745,21.3304292009,48.3829055154,84.8969143022,17.5368357974,44.4279188835,44.4279188835,44.4279188835,44.4279188835,13.8818796399,1.85231735,62.010898997,82.9524991369,12.219221176,44.3891879788,44.3891879788,44.3891879788,44.3891879788
6,1.7089118018,24.7722335595,49.0317632947,85.7753229808,20.2805201161,45.1224431389,45.1224431389,45.1224431389,45.1224431389,15.0596080459,1.8407398825,54.3733380235,83.2235460966,13.6280095327,44.3588643086,44.3588643086,44.3588643086,44.3588643086

Discussed with ChatGPT.  Since we have a lot of class imbalance, I want to try
adding weightings to the classes first.  We can also try regularization through
dropout, but I will try that later.  First I want to address the class imbalance
as it's quite severe:

[40728 40082 27889  6093  5745  4311  3073  2733  2512  2483  2346  1986
  1931  1927  1351  1117  1100   839   786   775   768   760   756   752
   691   684   641   637   615   532   526   476   466   462   454   451
 ...
     8     8     8     7     7     7     7     7     7     7     7     6
     6     6     6     6     6     5     5     4     4     4     4     3
     3     2     2     1]

I'm going to test changing my loss function to use class weights.

== Tue May 22 2023 ==
Added class weights.  The model's overall accuracy performance starts a lot
lower now compared to the previous model that quickly learnt to over-predict the
dominant classes.

Training accuracy after 6 epochs: 21% vs 45%
Validation accuracy after 6 epochs: 21% vs 44%

It's not clear that class weighting is actually something I should be using if I
just care about producing the best score possible on the test set.  Letting the
model learn the distribution of answers is resulting in much better performance.
However, I do want to try to improve my model's ability to actually learn the
VQA task in a general sense, so for now I will continue with weighted classes,
even if performance is worse, so that I can work on improving its actual ability
to learn.  Seeing the accuracy go up with weighted classes actually gives me
confidence that the model is truely learning how to answer the questions using
information from the image and text.

Later, when I want to try to get as high a score as possbile, I might reduce the
weighting, either remove it entirely or scale it back so they are partially
weighted.

== Tue 23rd May 2023 ==
Took a detour to implement fully automated resuming of training, and validating
of unvalidated snapshots, so that we are resilient to spot instance
interruption. This will accelerate the pace of my experimentation as I no longer
need to closely monitor training runs.

This involved adding DDB records for snapshot metadata to make them queryable,
so we can easily find new snapshots pending validation, as well as determine the latest
epoch we've trained up to, for resuming training.

After that, implemented dropout to try to address overfitting.  It hasn't seemed
to make much different when I compare the before and after.

== Wed 24th May 2023 ==

Added batch normalization.  Didn't make any noticeable difference.

Then, I had a thought.  Since I'm using answer classes, and each answer is only
represented by a different index in my final layer, the model has no knowledge
of the actual text corresponding to the answer.  As a human, I'm imagining how
hard it would be to do a multiple choice test where the answer text was hidden,
and you just had to figure out for yourself what each box might represent.  I
figured the model would benefit from actually knowing what the text was for each
answer.

So, upon discussion with ChatGPT, we decided to use BERT to generate a static
embedding for each answer class from its answer text.  Then, in our model,
instead just passing the question and image embeddings through a final linear
layer to produce logits, we instead produce our own embedding (of length 768;
same size as BERT) to be compared with the answer embeddings.  Then, the final
prediction layer computes a cosine similarity score from our model's embedding
to the 1000 answer embeddings.

The idea is to provide the model with semantically meaningful representations of
the answer classes, to help it not only understand that two classes are
different, but *how* they are different on a semantic level.

Now I trained this, but the accuracy is staying very low but moving around in an
unstable way.  Perhaps the learning rate needs to change now.

However, I'm going to take a break from training to implement an optimization
idea.  Rather than computing the BERT and ViT embeddings in the forward pass of
our model, since these weights are frozen I should be able to pre-compute them
once and store to disk.  Then keep them all in memory during training and just
feed the embeddings directly into my model.  Should hopefully be a huge speedup
for training.
